{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import entropy, skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, chi2, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder_path = 'data'\n",
    "\n",
    "data_frames = []\n",
    "\n",
    "for folder in os.listdir(root_folder_path):  # look for every folder in the root folder\n",
    "    folder_path = os.path.join(root_folder_path, folder)  # path for every folder: idle, running, etc.\n",
    "\n",
    "    for file_name in os.listdir(folder_path):  # look for every file in the folder\n",
    "        file_path = os.path.join(folder_path, file_name)  # path for every file in the folder\n",
    "\n",
    "        data = pd.read_csv(file_path, skiprows=0)  # read data from the file, skipping titles\n",
    "\n",
    "        data['target'] = folder  # add column with target: idle, running, stairs, or walking\n",
    "        data_frames.append(data)  # append every data to data_frames list\n",
    "\n",
    "all_data = pd.concat(data_frames, axis=0, ignore_index=True)  # add all data into the main DataFrame\n",
    "all_data.columns = ['X', 'Y', 'Z', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000776</td>\n",
       "      <td>4.616021</td>\n",
       "      <td>8.576031</td>\n",
       "      <td>idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.718261</td>\n",
       "      <td>4.209007</td>\n",
       "      <td>8.446744</td>\n",
       "      <td>idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.909797</td>\n",
       "      <td>-0.282516</td>\n",
       "      <td>9.203311</td>\n",
       "      <td>idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.099650</td>\n",
       "      <td>0.148441</td>\n",
       "      <td>8.418014</td>\n",
       "      <td>idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.762132</td>\n",
       "      <td>-0.162806</td>\n",
       "      <td>9.251195</td>\n",
       "      <td>idle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y         Z target\n",
       "0  1.000776  4.616021  8.576031   idle\n",
       "1  0.718261  4.209007  8.446744   idle\n",
       "2 -0.909797 -0.282516  9.203311   idle\n",
       "3  5.099650  0.148441  8.418014   idle\n",
       "4  1.762132 -0.162806  9.251195   idle"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193860, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512769</td>\n",
       "      <td>0.558895</td>\n",
       "      <td>0.609421</td>\n",
       "      <td>idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.509164</td>\n",
       "      <td>0.553702</td>\n",
       "      <td>0.607771</td>\n",
       "      <td>idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.488392</td>\n",
       "      <td>0.496395</td>\n",
       "      <td>0.617424</td>\n",
       "      <td>idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.565066</td>\n",
       "      <td>0.501894</td>\n",
       "      <td>0.607405</td>\n",
       "      <td>idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.522483</td>\n",
       "      <td>0.497923</td>\n",
       "      <td>0.618035</td>\n",
       "      <td>idle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y         Z target\n",
       "0  0.512769  0.558895  0.609421   idle\n",
       "1  0.509164  0.553702  0.607771   idle\n",
       "2  0.488392  0.496395  0.617424   idle\n",
       "3  0.565066  0.501894  0.607405   idle\n",
       "4  0.522483  0.497923  0.618035   idle"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data normalization\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = all_data.copy()\n",
    "normalized_data[['X', 'Y', 'Z']] = scaler.fit_transform(all_data[['X', 'Y', 'Z']])\n",
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalized_data[['X', 'Y', 'Z']]\n",
    "y = normalized_data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier = SVC()\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "svc_prediction = svc_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9185    85     0    36]\n",
      " [  362 27609     0  2638]\n",
      " [   13   372     4  1148]\n",
      " [   54  1531     0 15121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        idle       0.96      0.99      0.97      9306\n",
      "     running       0.93      0.90      0.92     30609\n",
      "      stairs       1.00      0.00      0.01      1537\n",
      "     walking       0.80      0.91      0.85     16706\n",
      "\n",
      "    accuracy                           0.89     58158\n",
      "   macro avg       0.92      0.70      0.69     58158\n",
      "weighted avg       0.90      0.89      0.88     58158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, svc_prediction)\n",
    "print(confusion_matrix)\n",
    "print(classification_report(y_test, svc_prediction, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier = RandomForestClassifier(n_estimators=10, max_depth=10, random_state=42)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "tree_prediction = tree_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9242    56     0     8]\n",
      " [   67 29034     0  1508]\n",
      " [    4   428   150   955]\n",
      " [   19   893     0 15794]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        idle       0.99      0.99      0.99      9306\n",
      "     running       0.95      0.95      0.95     30609\n",
      "      stairs       1.00      0.10      0.18      1537\n",
      "     walking       0.86      0.95      0.90     16706\n",
      "\n",
      "    accuracy                           0.93     58158\n",
      "   macro avg       0.95      0.75      0.76     58158\n",
      "weighted avg       0.94      0.93      0.92     58158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, tree_prediction)\n",
    "print(confusion_matrix)\n",
    "print(classification_report(y_test, tree_prediction, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x = []\n",
    "mean_y = []\n",
    "mean_z = []\n",
    "target = []\n",
    "variance_x = []\n",
    "variance_y = []\n",
    "variance_z = []\n",
    "std_x = []\n",
    "std_y = []\n",
    "std_z = []\n",
    "root_mean_square_x = []\n",
    "root_mean_square_y = []\n",
    "root_mean_square_z = []\n",
    "min_x = []\n",
    "min_y = []\n",
    "min_z = []\n",
    "max_x = []\n",
    "max_y = []\n",
    "max_z = []\n",
    "median_x = []\n",
    "median_y = []\n",
    "median_z = []\n",
    "\n",
    "fft_power_x = []\n",
    "fft_power_y = []\n",
    "fft_power_z = []\n",
    "fft_energy_x = []\n",
    "fft_energy_y = []\n",
    "fft_energy_z = []\n",
    "fft_magnitude_x = []\n",
    "fft_magnitude_y = []\n",
    "fft_magnitude_z = []\n",
    "fft_area_x = []\n",
    "fft_area_y = []\n",
    "fft_area_z = []\n",
    "fft_max_amplitude_x = []\n",
    "fft_max_amplitude_y = []\n",
    "fft_max_amplitude_z = []\n",
    "fft_min_amplitude_x = []\n",
    "fft_min_amplitude_y = []\n",
    "fft_min_amplitude_z = []\n",
    "fft_min_index_x = []\n",
    "fft_min_index_y = []\n",
    "fft_min_index_z = []\n",
    "fft_max_index_x = []\n",
    "fft_max_index_y = []\n",
    "fft_max_index_z = []\n",
    "fft_entropy_x = []\n",
    "fft_entropy_y = []\n",
    "fft_entropy_z = []\n",
    "fft_skewness_x = []\n",
    "fft_skewness_y = []\n",
    "fft_skewness_z = []\n",
    "fft_kurtosis_x = []\n",
    "fft_kurtosis_y = []\n",
    "fft_kurtosis_z = []\n",
    "fft_interquartile_range_x = []\n",
    "fft_interquartile_range_y = []\n",
    "fft_interquartile_range_z = []\n",
    "fft_mean_absolute_deviation_x = []\n",
    "fft_mean_absolute_deviation_y = []\n",
    "fft_mean_absolute_deviation_z = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in normalized_data.columns:\n",
    "    for i in range(0, len(normalized_data['X']), 30):\n",
    "\n",
    "        segment = normalized_data[column].loc[i:i+30]\n",
    "\n",
    "        if column == 'X':\n",
    "\n",
    "            mean_x.append(segment.mean())\n",
    "            min_x.append(segment.min())\n",
    "            max_x.append(segment.min())\n",
    "            median_x.append(np.median(segment))\n",
    "            variance_x.append(np.var(segment))\n",
    "            std_x.append(np.std(segment))\n",
    "            root_mean_square_x.append(np.sqrt(np.mean(np.square(segment))))\n",
    "\n",
    "            x_fft = np.fft.fft(segment, n=len(segment))\n",
    "\n",
    "            fft_power_x.append((np.mean(np.abs(x_fft) ** 2) / (2 * np.pi)))\n",
    "            fft_energy_x.append(np.sum(np.abs(x_fft) ** 2) / len(x_fft))\n",
    "\n",
    "            magnitude_x = np.abs(x_fft)\n",
    "            fft_magnitude_x.append(np.mean(magnitude_x))\n",
    "            fft_area_x.append(np.trapz(magnitude_x))\n",
    "\n",
    "            fft_max_amplitude_x.append(np.max(np.abs(x_fft)))\n",
    "            fft_min_amplitude_x.append(np.min(np.abs(x_fft)))\n",
    "\n",
    "            fft_max_index_x.append(np.argmax(np.abs(x_fft)))\n",
    "            fft_min_index_x.append(np.argmin(np.abs(x_fft)))\n",
    "\n",
    "            fft_entropy_x = entropy(np.abs(x_fft))\n",
    "            fft_skewness_x = skew(np.abs(x_fft))\n",
    "            fft_kurtosis_x = kurtosis(np.abs(x_fft))\n",
    "\n",
    "            fft_interquartile_range_x = np.percentile(np.abs(x_fft), 75) - np.percentile(np.abs(x_fft), 25)\n",
    "            fft_mean_absolute_deviation_x = np.mean(np.abs(np.abs(x_fft) - np.mean(np.abs(x_fft))))\n",
    "\n",
    "        elif column == 'Y':\n",
    "\n",
    "            mean_y.append(segment.mean())\n",
    "            min_y.append(segment.min())\n",
    "            max_y.append(segment.min())\n",
    "            median_y.append(np.median(segment))\n",
    "            variance_y.append(np.var(segment))\n",
    "            std_y.append(np.std(segment))\n",
    "            root_mean_square_y.append(np.sqrt(np.mean(np.square(segment))))\n",
    "\n",
    "            y_fft = np.fft.fft(segment, n=len(segment))\n",
    "\n",
    "            fft_power_y.append((np.mean(np.abs(y_fft) ** 2) / (2 * np.pi)))\n",
    "            fft_energy_y.append(np.sum(np.abs(y_fft) ** 2) / len(y_fft))\n",
    "\n",
    "            magnitude_y = np.abs(y_fft)\n",
    "            fft_magnitude_y.append(np.mean(magnitude_y))\n",
    "            fft_area_y.append(np.trapz(magnitude_y))\n",
    "\n",
    "            fft_max_amplitude_y.append(np.max(np.abs(y_fft)))\n",
    "            fft_min_amplitude_y.append(np.min(np.abs(y_fft)))\n",
    "\n",
    "            fft_max_index_y.append(np.argmax(np.abs(y_fft)))\n",
    "            fft_min_index_y.append(np.argmin(np.abs(y_fft)))\n",
    "\n",
    "            fft_entropy_y = entropy(np.abs(y_fft))\n",
    "            fft_skewness_y = skew(np.abs(y_fft))\n",
    "            fft_kurtosis_y = kurtosis(np.abs(y_fft))\n",
    "\n",
    "            fft_interquartile_range_y = np.percentile(np.abs(y_fft), 75) - np.percentile(np.abs(y_fft), 25)\n",
    "            fft_mean_absolute_deviation_y = np.mean(np.abs(np.abs(y_fft) - np.mean(np.abs(y_fft))))\n",
    "\n",
    "        elif column == 'Z':\n",
    "\n",
    "            mean_z.append(segment.mean())\n",
    "            min_z.append(segment.min())\n",
    "            max_z.append(segment.min())\n",
    "            median_z.append(np.median(segment))\n",
    "            variance_z.append(np.var(segment))\n",
    "            std_z.append(np.std(segment))\n",
    "            root_mean_square_z.append(np.sqrt(np.mean(np.square(segment))))\n",
    "\n",
    "            z_fft = np.fft.fft(segment, n=len(segment))\n",
    "\n",
    "            fft_power_z.append((np.mean(np.abs(z_fft) ** 2) / (2 * np.pi)))\n",
    "            fft_energy_z.append(np.sum(np.abs(z_fft) ** 2) / len(z_fft))\n",
    "\n",
    "            magnitude_z = np.abs(z_fft)\n",
    "            fft_magnitude_z.append(np.mean(magnitude_z))\n",
    "            fft_area_z.append(np.trapz(magnitude_z))\n",
    "\n",
    "            fft_max_amplitude_z.append(np.max(np.abs(z_fft)))\n",
    "            fft_min_amplitude_z.append(np.min(np.abs(z_fft)))\n",
    "\n",
    "            fft_max_index_z.append(np.argmax(np.abs(z_fft)))\n",
    "            fft_min_index_z.append(np.argmin(np.abs(z_fft)))\n",
    "\n",
    "            fft_entropy_z = entropy(np.abs(z_fft))\n",
    "            fft_skewness_z = skew(np.abs(z_fft))\n",
    "            fft_kurtosis_z = kurtosis(np.abs(z_fft))\n",
    "\n",
    "            fft_interquartile_range_z = np.percentile(np.abs(z_fft), 75) - np.percentile(np.abs(z_fft), 25)\n",
    "            fft_mean_absolute_deviation_z = np.mean(np.abs(np.abs(z_fft) - np.mean(np.abs(z_fft))))\n",
    "\n",
    "        elif column == 'target':\n",
    "            \n",
    "            target.append(normalized_data[column].loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'target': target,\n",
    "    'mean_x': mean_x,\n",
    "    'mean_y': mean_y,\n",
    "    'mean_z': mean_z,\n",
    "    'variance_x': variance_x,\n",
    "    'variance_y': variance_y,\n",
    "    'variance_z': variance_z,\n",
    "    'std_x': std_x,\n",
    "    'std_y': std_y,\n",
    "    'std_z': std_z,\n",
    "    'root_mean_square_x': root_mean_square_x,\n",
    "    'root_mean_square_y': root_mean_square_y,\n",
    "    'root_mean_square_z': root_mean_square_z,\n",
    "    'min_x': min_x,\n",
    "    'min_y': min_y,\n",
    "    'min_z': min_z,\n",
    "    'max_x': max_x,\n",
    "    'max_y': max_y,\n",
    "    'max_z': max_z,\n",
    "    'median_x': median_x,\n",
    "    'median_y': median_y,\n",
    "    'median_z': median_z,\n",
    "    'fft_power_x': fft_power_x,\n",
    "    'fft_power_y': fft_power_y,\n",
    "    'fft_power_z': fft_power_z,\n",
    "    'fft_energy_x': fft_energy_x,\n",
    "    'fft_energy_y': fft_energy_y,\n",
    "    'fft_energy_z': fft_energy_z,\n",
    "    'fft_magnitude_x': fft_magnitude_x,\n",
    "    'fft_magnitude_y': fft_magnitude_y,\n",
    "    'fft_magnitude_z': fft_magnitude_z,\n",
    "    'fft_area_x': fft_area_x,\n",
    "    'fft_area_y': fft_area_y,\n",
    "    'fft_area_z': fft_area_z,\n",
    "    'fft_max_amplitude_x': fft_max_amplitude_x,\n",
    "    'fft_max_amplitude_y': fft_max_amplitude_y,\n",
    "    'fft_max_amplitude_z': fft_max_amplitude_z,\n",
    "    'fft_min_amplitude_x': fft_min_amplitude_x,\n",
    "    'fft_min_amplitude_y': fft_min_amplitude_y,\n",
    "    'fft_min_amplitude_z': fft_min_amplitude_z,\n",
    "    'fft_min_index_x': fft_min_index_x,\n",
    "    'fft_min_index_y': fft_min_index_y,\n",
    "    'fft_min_index_z': fft_min_index_z,\n",
    "    'fft_max_index_x': fft_max_index_x,\n",
    "    'fft_max_index_y': fft_max_index_y,\n",
    "    'fft_max_index_z': fft_max_index_z,\n",
    "    'fft_entropy_x': fft_entropy_x,\n",
    "    'fft_entropy_y': fft_entropy_y,\n",
    "    'fft_entropy_z': fft_entropy_z,\n",
    "    'fft_skewness_x': fft_skewness_x,\n",
    "    'fft_skewness_y': fft_skewness_y,\n",
    "    'fft_skewness_z': fft_skewness_z,\n",
    "    'fft_kurtosis_x': fft_kurtosis_x,\n",
    "    'fft_kurtosis_y': fft_kurtosis_y,\n",
    "    'fft_kurtosis_z': fft_kurtosis_z,\n",
    "    'fft_interquartile_range_x': fft_interquartile_range_x,\n",
    "    'fft_interquartile_range_y': fft_interquartile_range_y,\n",
    "    'fft_interquartile_range_z': fft_interquartile_range_z,\n",
    "    'fft_mean_absolute_deviation_x': fft_mean_absolute_deviation_x,\n",
    "    'fft_mean_absolute_deviation_y': fft_mean_absolute_deviation_y,\n",
    "    'fft_mean_absolute_deviation_z': fft_mean_absolute_deviation_z\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>mean_x</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>mean_z</th>\n",
       "      <th>variance_x</th>\n",
       "      <th>variance_y</th>\n",
       "      <th>variance_z</th>\n",
       "      <th>std_x</th>\n",
       "      <th>std_y</th>\n",
       "      <th>std_z</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_skewness_z</th>\n",
       "      <th>fft_kurtosis_x</th>\n",
       "      <th>fft_kurtosis_y</th>\n",
       "      <th>fft_kurtosis_z</th>\n",
       "      <th>fft_interquartile_range_x</th>\n",
       "      <th>fft_interquartile_range_y</th>\n",
       "      <th>fft_interquartile_range_z</th>\n",
       "      <th>fft_mean_absolute_deviation_x</th>\n",
       "      <th>fft_mean_absolute_deviation_y</th>\n",
       "      <th>fft_mean_absolute_deviation_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>idle</td>\n",
       "      <td>0.502162</td>\n",
       "      <td>0.502016</td>\n",
       "      <td>0.622623</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>2.534090e-05</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>0.014301</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>...</td>\n",
       "      <td>5.181363</td>\n",
       "      <td>24.909131</td>\n",
       "      <td>24.550209</td>\n",
       "      <td>24.913634</td>\n",
       "      <td>0.214499</td>\n",
       "      <td>0.257444</td>\n",
       "      <td>0.164945</td>\n",
       "      <td>0.977613</td>\n",
       "      <td>0.693352</td>\n",
       "      <td>0.938221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idle</td>\n",
       "      <td>0.498743</td>\n",
       "      <td>0.498477</td>\n",
       "      <td>0.624667</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.869336e-08</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>...</td>\n",
       "      <td>5.181363</td>\n",
       "      <td>24.909131</td>\n",
       "      <td>24.550209</td>\n",
       "      <td>24.913634</td>\n",
       "      <td>0.214499</td>\n",
       "      <td>0.257444</td>\n",
       "      <td>0.164945</td>\n",
       "      <td>0.977613</td>\n",
       "      <td>0.693352</td>\n",
       "      <td>0.938221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  target    mean_x    mean_y    mean_z  variance_x  variance_y    variance_z  \\\n",
       "0   idle  0.502162  0.502016  0.622623    0.000164    0.000205  2.534090e-05   \n",
       "1   idle  0.498743  0.498477  0.624667    0.000002    0.000001  9.869336e-08   \n",
       "\n",
       "      std_x     std_y     std_z  ...  fft_skewness_z  fft_kurtosis_x  \\\n",
       "0  0.012805  0.014301  0.005034  ...        5.181363       24.909131   \n",
       "1  0.001553  0.001016  0.000314  ...        5.181363       24.909131   \n",
       "\n",
       "   fft_kurtosis_y  fft_kurtosis_z  fft_interquartile_range_x  \\\n",
       "0       24.550209       24.913634                   0.214499   \n",
       "1       24.550209       24.913634                   0.214499   \n",
       "\n",
       "   fft_interquartile_range_y  fft_interquartile_range_z  \\\n",
       "0                   0.257444                   0.164945   \n",
       "1                   0.257444                   0.164945   \n",
       "\n",
       "   fft_mean_absolute_deviation_x  fft_mean_absolute_deviation_y  \\\n",
       "0                       0.977613                       0.693352   \n",
       "1                       0.977613                       0.693352   \n",
       "\n",
       "   fft_mean_absolute_deviation_z  \n",
       "0                       0.938221  \n",
       "1                       0.938221  \n",
       "\n",
       "[2 rows x 61 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_new_features = pd.DataFrame(data)\n",
    "data_with_new_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6462, 61)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_new_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_with_new_features.iloc[:, 1:]\n",
    "y = data_with_new_features['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5169, 60), (1293, 60), (5169,), (1293,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat((X_train, y_train), axis = 1)\n",
    "test_data = pd.concat((X_test, y_test), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With new features, with selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_svc = Pipeline([\n",
    "    ('chi-square', SelectKBest(chi2, k=10) ),\n",
    "    ('mutual_info_classif', SelectKBest(score_func=mutual_info_classif, k=10)),\n",
    "    ('f_classif', SelectKBest(score_func=f_classif, k=10)),\n",
    "    ('svc', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_svc.fit(X_train, y_train)\n",
    "svc_prediction = feature_selection_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[220   0   0   0]\n",
      " [  0 689   0   0]\n",
      " [  0   0   5  25]\n",
      " [  0   0   0 354]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        idle       1.00      1.00      1.00       220\n",
      "     running       1.00      1.00      1.00       689\n",
      "      stairs       1.00      0.17      0.29        30\n",
      "     walking       0.93      1.00      0.97       354\n",
      "\n",
      "    accuracy                           0.98      1293\n",
      "   macro avg       0.98      0.79      0.81      1293\n",
      "weighted avg       0.98      0.98      0.97      1293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, svc_prediction)\n",
    "print(confusion_matrix)\n",
    "print(classification_report(y_test, svc_prediction, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_tree = Pipeline([\n",
    "    ('chi-square', SelectKBest(chi2, k=15) ),\n",
    "    ('mutual_info_classif', SelectKBest(score_func=mutual_info_classif, k=15)),\n",
    "    ('f_classif', SelectKBest(score_func=f_classif, k=15)),\n",
    "    ('tree', RandomForestClassifier(n_estimators=10, max_depth=10, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_tree.fit(X_train, y_train)\n",
    "tree_prediction = feature_selection_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[220   0   0   0]\n",
      " [  0 689   0   0]\n",
      " [  0   0  23   7]\n",
      " [  0   0   4 350]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        idle       1.00      1.00      1.00       220\n",
      "     running       1.00      1.00      1.00       689\n",
      "      stairs       0.85      0.77      0.81        30\n",
      "     walking       0.98      0.99      0.98       354\n",
      "\n",
      "    accuracy                           0.99      1293\n",
      "   macro avg       0.96      0.94      0.95      1293\n",
      "weighted avg       0.99      0.99      0.99      1293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, tree_prediction)\n",
    "print(confusion_matrix)\n",
    "print(classification_report(y_test, tree_prediction, zero_division=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
